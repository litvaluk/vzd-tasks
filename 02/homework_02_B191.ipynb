{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Úkol č. 2 - předzpracování dat a binární klasifikace (do 10. listopadu)\n",
    "\n",
    "  * Cílem thoto úkolu je vyzkoušet si naučit prediktivní model pro binární klasifikaci.\n",
    "  * Budete se muset vypořádat s příznaky, které jsou různých typů a které bude třeba nějakým způsobem převést do číselné reprezentace.\n",
    "    \n",
    "> **Úkoly jsou zadány tak, aby Vám daly prostor pro invenci. Vymyslet _jak přesně_ budete úkol řešit, je důležitou součástí zadání a originalita či nápaditost bude také hodnocena!**\n",
    "\n",
    "## Zdroj dat\n",
    "\n",
    "Budeme se zabývat predikcí přežití pasažérů Titaniku.\n",
    "K dispozici máte trénovací data v souboru **data.csv** a data na vyhodnocení v souboru **evaluation.csv**.\n",
    "\n",
    "#### Seznam příznaků:\n",
    "* survived - zda přežil, 0 = Ne, 1 = Ano, **vysvětlovaná proměnná**, kterou chcete predikovat\n",
    "* pclass - Třída lodního lístku, 1 = první, 2 = druhá, 3 = třetí\n",
    "* name - jméno\n",
    "* sex - pohlaví\n",
    "* age - věk v letech\n",
    "* sibsp\t- počet sourozenců / manželů, manželek na palubě\n",
    "* parch - počet rodičů / dětí na palubě\n",
    "* ticket - číslo lodního lístku\n",
    "* fare - cena lodního lístku\n",
    "* cabin\t- číslo kajuty\n",
    "* embarked\t- místo nalodění, C = Cherbourg, Q = Queenstown, S = Southampton\n",
    "* home.dest - Bydliště/Cíl\n",
    "\n",
    "## Pokyny k vypracování\n",
    "\n",
    "**Základní body zadání**, za jejichž (poctivé) vypracování získáte **8 bodů**:\n",
    "  * V Jupyter notebooku načtěte data ze souboru **data.csv**. Vhodným způsobem si je rozdělte na trénovací, testovací a případně i validační množinu (preferujeme ale použití cross-validation).\n",
    "  * Projděte si jednotlivé příznaky a transformujte je do vhodné podoby pro použití ve vybraném klasifikačním modelu.\n",
    "  * Podle potřeby si můžete vytvářet nové příznaky (na základě existujících), například tedy můžete vytvořit příznak měřící délku jména. Některé příznaky můžete také úplně zahodit.\n",
    "  * Nějakým způsobem se vypořádejte s chybějícími hodnotami.\n",
    "  * Následně si vyberte vhodný klasifikační model z přednášek. Najděte vhodné hyperparametry a určete jeho přesnost (accuracy) na trénovací množině. Také určete jeho přesnost na testovací/vaidační množině.\n",
    "  * Načtěte vyhodnocovací data ze souboru **evaluation.csv**. Napočítejte predikce pro tyto data (vysvětlovaná proměnná v nich již není). Vytvořte **results.csv** soubor, ve kterém tyto predikce uložíte do dvou sloupců: ID, predikce přežití. Tento soubor nahrajte do repozitáře.\n",
    "\n",
    "**Další body zadání** za případné další body  (můžete si vybrat, maximum bodů za úkol je každopádně 12 bodů):\n",
    "  * (až +4 body) Aplikujte všechny klasifikační modely z přednášek a určete (na základě přesnosti na validační množině), který je nejlepší. Přesnost tohoto nejlepšího modelu odhadněte pomocí testovací množiny. K predikcím na vyhodnocovacích datech využijte tento model.\n",
    "  * (až +4 body) Zkuste použít nějaké (alespoň dvě) netriviální metody doplňování chybějících hodnot u věku. Zaměřte na vliv těchto metod na přesnost predikce výsledného modelu. K predikcím na vyhodnocovacích datech využijte ten přístup, který Vám vyjde jako nejlepší.\n",
    "\n",
    "## Poznámky k odevzdání\n",
    "\n",
    "  * Řiďte se pokyny ze stránky https://courses.fit.cvut.cz/BI-VZD/homeworks/index.html.\n",
    "  * Odevzdejte nejen Jupyter Notebook, ale i _csv_ soubor(y) s predikcemi pro vyhodnocovací data.\n",
    "  * Opravující Vám může umožnit úkol dodělat či opravit a získat tak další body. **První verze je ale důležitá a bude-li odbytá, budete za to penalizováni**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Řešení"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# display(data.shape)\n",
    "# display(data.head())\n",
    "# display(data.info())\n",
    "# display(data.describe())\n",
    "# display(data.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column adjustments\n",
    "string_cols = data.select_dtypes(['object']).columns\n",
    "data[string_cols] = data[string_cols].astype('category').apply(lambda x: x.cat.codes)\n",
    "data[\"fare\"] = data[\"fare\"].fillna(-1)\n",
    "data[\"age\"] = data[\"age\"].fillna(-1)\n",
    "\n",
    "# data.info()\n",
    "# display(data.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xdata = data.copy()\n",
    "Xdata = Xdata.drop(\"survived\", axis=1)\n",
    "ydata = data.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data to train/validation/test\n",
    "rd_seed = 333\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(Xdata, ydata, test_size=0.25, random_state=rd_seed)\n",
    "Xtrain, Xval, ytrain, yval = train_test_split(Xtrain, ytrain, test_size=0.25, random_state=rd_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_comb = ParameterGrid({\n",
    "    'max_depth': range(1,30), \n",
    "    'criterion': ['entropy', 'gini']\n",
    "})\n",
    "\n",
    "val_acc = []\n",
    "train_acc = []\n",
    "for params in param_comb:\n",
    "    dt = DecisionTreeClassifier(max_depth=params['max_depth'], criterion=params['criterion'])\n",
    "    dt.fit(Xtrain, ytrain)\n",
    "    train_acc.append(metrics.accuracy_score(ytrain, dt.predict(Xtrain)))\n",
    "    val_acc.append(metrics.accuracy_score(yval, dt.predict(Xval)))\n",
    "    \n",
    "plt.figure(figsize=(20,6))\n",
    "plt.plot(train_acc,'or-')\n",
    "plt.plot(val_acc,'ob-')\n",
    "plt.xlabel('hyperparametr index')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['train', 'validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = param_comb[np.argmax(val_acc)]\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(**best_params)\n",
    "dt.fit(Xtrain, ytrain)\n",
    "print('accuracy score (train): {0:.6f}'.format(metrics.accuracy_score(ytrain, dt.predict(Xtrain))))\n",
    "print('accuracy score (validation): {0:.6f}'.format(metrics.accuracy_score(yval, dt.predict(Xval))))\n",
    "print('accuracy score (test): {0:.6f}'.format(metrics.accuracy_score(ytest, dt.predict(Xtest))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_comb = ParameterGrid({\n",
    "    'max_depth': range(1,10), \n",
    "    'criterion': ['entropy', 'gini'],\n",
    "    'n_estimators': range(1,50,5)\n",
    "})\n",
    "\n",
    "val_acc = []\n",
    "train_acc = []\n",
    "for params in param_comb:\n",
    "    dt = RandomForestClassifier(max_depth=params['max_depth'],\n",
    "                                criterion=params['criterion'],\n",
    "                                n_estimators=params['n_estimators'])\n",
    "    dt.fit(Xtrain, ytrain)\n",
    "    train_acc.append(metrics.accuracy_score(ytrain, dt.predict(Xtrain)))\n",
    "    val_acc.append(metrics.accuracy_score(yval, dt.predict(Xval)))\n",
    "    \n",
    "plt.figure(figsize=(20,6))\n",
    "plt.plot(train_acc,'or-')\n",
    "plt.plot(val_acc,'ob-')\n",
    "plt.xlabel('hyperparametr index')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['train', 'validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = param_comb[np.argmax(val_acc)]\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = RandomForestClassifier(**best_params)\n",
    "dt.fit(Xtrain, ytrain)\n",
    "print('accuracy score (train): {0:.6f}'.format(metrics.accuracy_score(ytrain, dt.predict(Xtrain))))\n",
    "print('accuracy score (validation): {0:.6f}'.format(metrics.accuracy_score(yval, dt.predict(Xval))))\n",
    "print('accuracy score (test): {0:.6f}'.format(metrics.accuracy_score(ytest, dt.predict(Xtest))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_comb = ParameterGrid({\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.3, 0.5, 1],\n",
    "    'n_estimators': range(1,50,5)\n",
    "})\n",
    "\n",
    "val_acc = []\n",
    "train_acc = []\n",
    "for params in param_comb:\n",
    "    dt = AdaBoostClassifier(learning_rate=params['learning_rate'], n_estimators=params['n_estimators'])\n",
    "    dt.fit(Xtrain, ytrain)\n",
    "    train_acc.append(metrics.accuracy_score(ytrain, dt.predict(Xtrain)))\n",
    "    val_acc.append(metrics.accuracy_score(yval, dt.predict(Xval)))\n",
    "    \n",
    "plt.figure(figsize=(20,6))\n",
    "plt.plot(train_acc,'or-')\n",
    "plt.plot(val_acc,'ob-')\n",
    "plt.xlabel('hyperparametr index')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['train', 'validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = param_comb[np.argmax(val_acc)]\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = AdaBoostClassifier(**best_params)\n",
    "dt.fit(Xtrain, ytrain)\n",
    "print('accuracy score (train): {0:.6f}'.format(metrics.accuracy_score(ytrain, dt.predict(Xtrain))))\n",
    "print('accuracy score (validation): {0:.6f}'.format(metrics.accuracy_score(yval, dt.predict(Xval))))\n",
    "print('accuracy score (test): {0:.6f}'.format(metrics.accuracy_score(ytest, dt.predict(Xtest))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
